# ğŸ“˜ Databricks: Mount and Unmount 
## ğŸ”‘ What is Mount in Databricks?
Mounting means connecting a storage location (like Azure Data Lake, AWS S3, etc.) to DBFS (Databricks File System), so you can access it like a folder.

### ğŸ”“ Real-Life Example:
Imagine you rent a storage unit (like Azure Data Lake).
You keep your boxes (data) there.
Mounting is like creating a shortcut in your house (Databricks) to access that storage unit directly â€” so you donâ€™t need to go outside every time.

### ğŸ§  Why Use Mounting?
- You donâ€™t have to write credentials every time.

- Easy to read/write data using normal paths.

- Works like a local folder: /mnt/your-mount-name

### âœ… Syntax to Mount a Storage Location:
```
dbutils.fs.mount(
  source = "your-cloud-path",  
  mount_point = "/mnt/mymount",  
  extra_configs = {"key": "value"}  # Authentication credentials
)
```
### ğŸ§¹ Syntax to Unmount:
`dbutils.fs.unmount("/mnt/mymount")`
- This disconnects the mount from DBFS.

## ğŸš€ Real-Life Scenarios Where Mounting is Used:

### ğŸ§Š 1. Data in Azure Data Lake (ADLS)
**Example:**
- You store data in Azure container rawdata under storage account myaccount.

Mount command:
```
dbutils.fs.mount(
  source = "wasbs://rawdata@myaccount.blob.core.windows.net/",
  mount_point = "/mnt/raw",
  extra_configs = {"fs.azure.account.key.myaccount.blob.core.windows.net": "your_access_key"}
)
```
### ğŸ’¡ Questions Wasbs vs abfss 
Youâ€™ve seen `wasbs://` and `abfss://` â€” both are used to connect to Azure storage, but they mean different things.

|**Protocol**|	**Stands For** |	**Used With** |**Supports Mount?**|	**Secure?**|
|--------|----------|--------|--------|-----|
|***wasbs://***|	Windows Azure Storage Blob over HTTPS |Azure Blob Storage (classic) |	âœ… Yes |	ğŸš« Less secure |
| ***abfss://*** |	Azure Blob File System Secure |	Azure Data Lake Storage Gen2 |	âŒ No  (use direct access) |	âœ… More secure |

**ğŸ” What is `wasbs://?`**
- ğŸ“¦ Used for Azure Blob Storage

- âœ… Can be used with dbutils.fs.mount()

- ğŸ‘´ Legacy style (older than ADLS Gen2)

- ğŸ”‘ Needs storage account key for authentication

- âŒ Not optimized for big data and hierarchical file systems
**Example**
`wasbs://<container-name>@<account-name>.blob.core.windows.net/`

**ğŸ” What is abfss://?**
- ğŸš€ Used for Azure Data Lake Storage Gen2

- âŒ Cannot be used with dbutils.fs.mount() (Databricks says no mount with abfss)

- âœ… Best for secure, modern, and high-performance data access

- ğŸ” Uses Azure Active Directory (AAD) + OAuth tokens (not storage key)

- ğŸ§± Supports hierarchical namespace (folders within folders)

**Example**
`abfss://<container-name>@<account-name>.dfs.core.windows.net/
`\

**ğŸ”„ So When to Use What?**
|**Situation**|	**Use This Protocol**|	**Why?**|
|-----------|-----------|-------------|
|Mounting with access key |	wasbs:// |	|Supports dbutils.fs.mount()|
|Direct read from ADLS Gen2 |	abfss:// |	 Secure, supports AAD + OAuth |
|You want fast, secure access |	abfss:// |	Best for production & big data |
| Legacy blob storage	| wasbs:// |	Works well with older accounts |
 
 ### ğŸ§  Tip for Memory:
- wasbs = "W" for Weak security (uses key)

- abfss = "A" for Azure AD + Advanced Security

### âœ… Pro Tip:
- If youâ€™re working with **modern ADLS Gen2**, use abfss:// for direct access, not mounting.
- If you **must mount**, and you're okay with using a storage key, use wasbs://.

### ğŸŒ² 2. Data in AWS S3
Mounting S3 is less recommended due to security and performance concerns â€” use direct access (read below in scenarios).

But if needed, it works like this:
```
dbutils.fs.mount(
  source = "s3a://your-bucket-name",
  mount_point = "/mnt/mybucket",
  extra_configs = {"fs.s3a.access.key": "your_access_key", "fs.s3a.secret.key": "your_secret_key"}
)
```

### â˜ï¸ 3. Accessing Data Without Mount (Direct Read)
Sometimes you donâ€™t mount at all, and just read the data directly from its location (best for S3, API, etc.).
**Example**
`df = spark.read.json("s3a://my-bucket-name/data.json")`

**This is used when:**

- You donâ€™t want to store credentials.
- You use temporary credentials (like tokens).
- You read from API responses or external services.

### ğŸ›°ï¸ 4. Data from API â€“ No Mount Needed
If your data comes from an API:

- You call the API using requests or similar library.

- You convert the response to a DataFrame.

- Mounting doesnâ€™t apply here.

```
import requests
import json

response = requests.get("https://api.example.com/data")
data = response.json()
df = spark.createDataFrame(data)
```
âœ… No mount needed because you're getting data in memory, not from storage.

## ğŸ“ When to Use Mount vs. Direct Access?

|Use Case |	Use Mount? |	Why? |
|---------|------------|---------|
|Azure Blob or Data Lake |	âœ… Yes |	Works well with dbutils.fs.mount |
|AWS S3 (small usage) 	|âŒ Prefer Direct |	Better for security, flexibility |
|API Data |	âŒ No |	You pull data via HTTP, not files|
|Temporary Credential Use |	âŒ No |	Mounting stores secrets longer |
|Frequent data access|	âœ… Yes|	Speeds up file path usage|
|Rare or one-time access |	âŒ No |	Mounting is unnecessary overhead|

## ğŸ§ª Bonus: Check Mounted Folders  
`display(dbutils.fs.mounts())`

## ğŸ§¼ Clean Up: Unmount When Not Needed
`dbutils.fs.unmount("/mnt/raw")`

Why unmount?
- Save clutter

- Reset connections

- Rotate credentials

